{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e8fac08a-e5a2-4937-976d-04642c77e5f9",
    "_uuid": "a3d20745-3597-4070-acb9-a70c64ca447c"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/working'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0f5e563d-1918-431c-8699-d8d6cc0a4c1e",
    "_uuid": "0407a5e0-0998-4501-a43b-0bd3d51b1da2"
   },
   "outputs": [],
   "source": [
    "!apt install bzip2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ad1ff951-e93f-4793-8735-131ea87266b5",
    "_uuid": "2fa2848d-0c26-4477-b6e8-1450924c428c"
   },
   "outputs": [],
   "source": [
    "!wget http://wikipedia2vec.s3.amazonaws.com/models/zh/2018-04-20/zhwiki_20180420_300d.txt.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0f726d10-3b7b-4621-a72a-3d433b001941",
    "_uuid": "1171b104-f175-4985-b3a0-49129468c677"
   },
   "outputs": [],
   "source": [
    "!pip install wikipedia2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "87fb57f0-07bb-47d3-8826-039675487e8d",
    "_uuid": "b7f24b3c-34bd-43f6-8ff7-dd8230690533"
   },
   "outputs": [],
   "source": [
    "!bzip2 -d /kaggle/working/zhwiki_20180420_300d.txt.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "737e98f8-1ddf-4067-82d1-128ff99933e4",
    "_uuid": "9062dbde-a784-4e84-8b79-39e13c2385a2"
   },
   "outputs": [],
   "source": [
    "from wikipedia2vec import Wikipedia2Vec\n",
    "model_ext = Wikipedia2Vec.load_text('/kaggle/working/zhwiki_20180420_300d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9d9fc66a-9ede-4bab-9219-c31fe0ea6f7c",
    "_uuid": "89158288-e72e-410e-a9b9-5d5601c9cb80"
   },
   "outputs": [],
   "source": [
    "def single_comment_words_construct(comment_cut_path):\n",
    "    comment_distinct_words = set([])\n",
    "    with open(comment_cut_path, \"r\") as f:\n",
    "        idx = 0\n",
    "        while True:\n",
    "            line = f.readline()\n",
    "            if line:\n",
    "                idx += 1\n",
    "                if idx > 0 and idx % 100000 == 0:\n",
    "                    print(\"read num {} set size {}\".format(idx, len(comment_distinct_words)))\n",
    "                for w in line.split(\" \"):\n",
    "                    comment_distinct_words.add(w)\n",
    "            else:\n",
    "                break\n",
    "    return comment_distinct_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c6bc2606-66b0-4f6b-8af0-c44d8561cd58",
    "_uuid": "034e4cd3-c8af-44c6-8d42-c4135e9bcb02"
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from glob import glob\n",
    "import os\n",
    "comment_distinct_words = reduce(lambda a, b: a.union(b) ,map(single_comment_words_construct, glob(os.path.join(\"/kaggle/input/douban-comment-cut-split\", \"*\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "58a5c9f9-a661-409f-9603-384cb88b4a40",
    "_uuid": "8368370c-136f-459e-a81e-a36d58a62e0c"
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "KeyedVectors_ext = KeyedVectors(vector_size=model_ext.get_word_vector(u\"中国\").shape[0])\n",
    "flush_size = 10000 \n",
    "words, vectors = [], []\n",
    "def get_wrapper(word_text):\n",
    "    req = None\n",
    "    try:\n",
    "        req = model_ext.get_word_vector(word_text)\n",
    "    except:\n",
    "        pass\n",
    "    return req\n",
    "for word_text in comment_distinct_words:\n",
    "    vec = get_wrapper(word_text)\n",
    "    if vec is not None:\n",
    "        words.append(word_text)\n",
    "        vectors.append(vec)\n",
    "    if len(words) >= flush_size:\n",
    "        print(\"flush {} into\".format(len(words)))\n",
    "        KeyedVectors_ext.add(words, vectors)\n",
    "        words, vectors = [], []\n",
    "KeyedVectors_ext.add(words, vectors)\n",
    "len(KeyedVectors_ext.vocab), len(comment_distinct_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9bea28e0-d61b-4660-9f91-40e26cca4c05",
    "_uuid": "d80b205e-b50b-4e56-bdcb-c6dad1b21973"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "w2v_model = Word2Vec(size = KeyedVectors_ext.wv[u\"中国\"].shape[0], min_count=1)\n",
    "w2v_model.build_vocab([list(comment_distinct_words)], update=False)\n",
    "len(w2v_model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "22a8a56d-a5a4-4473-851c-5cc49bff543e",
    "_uuid": "34655db2-c31f-43e2-830c-399145fde348"
   },
   "outputs": [],
   "source": [
    "for k in KeyedVectors_ext.vocab.keys():\n",
    "    w2v_model.wv.syn0[w2v_model.wv.vocab[k].index] = KeyedVectors_ext.wv[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "42b40be0-7bcb-4b9e-bc74-735b3126d4c1",
    "_uuid": "222cdbc3-ecac-481f-a39f-18843823b81c"
   },
   "outputs": [],
   "source": [
    "def iter_one_time(w2v_model, file_path = None):\n",
    "    if file_path is None:\n",
    "        file_path = np.random.choice(glob(os.path.join(\"/kaggle/input/douban-comment-cut-split\", \"*\")))\n",
    "    sentences = read_tiny_file_to_sentences(file_path)\n",
    "    w2v_model.train(sentences, epochs=5, total_examples=len(sentences))\n",
    "    return w2v_model\n",
    "\n",
    "def read_tiny_file_to_sentences(tiny_file):\n",
    "    with open(tiny_file, \"r\") as f:\n",
    "        return list(map(lambda x: x.strip().split(\" \") ,f.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_times = int(1e6)\n",
    "save_every = 3\n",
    "w2v_save_path = \"w2v_douban.model\"\n",
    "if os.path.exists(w2v_save_path):\n",
    "    os.remove(w2v_save_path)\n",
    "for run_time in range(run_times):\n",
    "    w2v_model = iter_one_time(w2v_model)\n",
    "    if run_time > 0 and run_time % save_every == 0:\n",
    "        w2v_model.save(w2v_save_path)\n",
    "        print(\"save {} to {}\".format(run_time ,w2v_save_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
