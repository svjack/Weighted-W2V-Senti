{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import datapath\n",
    "wv_from_text = KeyedVectors.load_word2vec_format(datapath('word2vec_pre_kv_c'), binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.models.keyedvectors.Word2VecKeyedVectors"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(wv_from_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.models.word2vec.Word2Vec"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Phrases in module gensim.models.phrases:\n",
      "\n",
      "class Phrases(SentenceAnalyzer, PhrasesTransformation)\n",
      " |  Detect phrases based on collocation counts.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Phrases\n",
      " |      SentenceAnalyzer\n",
      " |      PhrasesTransformation\n",
      " |      gensim.interfaces.TransformationABC\n",
      " |      gensim.utils.SaveLoad\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getitem__(self, sentence)\n",
      " |      Convert the input tokens `sentence` into tokens where detected bigrams are joined by a selected delimiter.\n",
      " |      \n",
      " |      If `sentence` is an entire corpus (iterable of sentences rather than a single\n",
      " |      sentence), return an iterable that converts each of the corpus' sentences\n",
      " |      into phrases on the fly, one after another.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sentence : {list of str, iterable of list of str}\n",
      " |          Sentence or text corpus.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      {list of str, :class:`gensim.interfaces.TransformedCorpus`}\n",
      " |          `sentence` with detected phrase bigrams merged together, or a streamed corpus of such sentences\n",
      " |          if the input was a corpus.\n",
      " |      \n",
      " |      Examples\n",
      " |      ----------\n",
      " |      >>> from gensim.test.utils import datapath\n",
      " |      >>> from gensim.models.word2vec import Text8Corpus\n",
      " |      >>> from gensim.models.phrases import Phrases, Phraser\n",
      " |      >>>\n",
      " |      >>> #Create corpus\n",
      " |      >>> sentences = Text8Corpus(datapath('testcorpus.txt'))\n",
      " |      >>>\n",
      " |      >>> #Train the detector with:\n",
      " |      >>> phrases = Phrases(sentences, min_count=1, threshold=1)\n",
      " |      >>> #Input is a list of unicode strings:\n",
      " |      >>> sent = [u'trees', u'graph', u'minors']\n",
      " |      >>> #Both of these tokens appear in corpus at least twice, and phrase score is higher, than treshold = 1:\n",
      " |      >>> print(phrases[sent])\n",
      " |      [u'trees_graph', u'minors']\n",
      " |      >>>\n",
      " |      >>> sentences = Text8Corpus(datapath('testcorpus.txt'))\n",
      " |      >>> phrases = Phrases(sentences, min_count=1, threshold=1)\n",
      " |      >>> phraser = Phraser(phrases)  # for speedup\n",
      " |      >>>\n",
      " |      >>> sent = [[u'trees', u'graph', u'minors'],[u'graph', u'minors']]\n",
      " |      >>> for phrase in phraser[sent]:\n",
      " |      ...     pass\n",
      " |  \n",
      " |  __init__(self, sentences=None, min_count=5, threshold=10.0, max_vocab_size=40000000, delimiter=b'_', progress_per=10000, scoring='default', common_terms=frozenset())\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sentences : iterable of list of str, optional\n",
      " |          The `sentences` iterable can be simply a list, but for larger corpora, consider a generator that streams\n",
      " |          the sentences directly from disk/network, See :class:`~gensim.models.word2vec.BrownCorpus`,\n",
      " |          :class:`~gensim.models.word2vec.Text8Corpus` or :class:`~gensim.models.word2vec.LineSentence`\n",
      " |          for such examples.\n",
      " |      min_count : float, optional\n",
      " |          Ignore all words and bigrams with total collected count lower than this value.\n",
      " |      threshold : float, optional\n",
      " |          Represent a score threshold for forming the phrases (higher means fewer phrases).\n",
      " |          A phrase of words `a` followed by `b` is accepted if the score of the phrase is greater than threshold.\n",
      " |          Heavily depends on concrete scoring-function, see the `scoring` parameter.\n",
      " |      max_vocab_size : int, optional\n",
      " |          Maximum size (number of tokens) of the vocabulary. Used to control pruning of less common words,\n",
      " |          to keep memory under control. The default of 40M needs about 3.6GB of RAM. Increase/decrease\n",
      " |          `max_vocab_size` depending on how much available memory you have.\n",
      " |      delimiter : str, optional\n",
      " |          Glue character used to join collocation tokens, should be a byte string (e.g. b'_').\n",
      " |      scoring : {'default', 'npmi', function}, optional\n",
      " |          Specify how potential phrases are scored. `scoring` can be set with either a string that refers to a\n",
      " |          built-in scoring function, or with a function with the expected parameter names.\n",
      " |          Two built-in scoring functions are available by setting `scoring` to a string:\n",
      " |      \n",
      " |          #. \"default\" - :func:`~gensim.models.phrases.original_scorer`.\n",
      " |          #. \"npmi\" - :func:`~gensim.models.phrases.npmi_scorer`.\n",
      " |      common_terms : set of str, optional\n",
      " |          List of \"stop words\" that won't affect frequency count of expressions containing them.\n",
      " |          Allow to detect expressions like \"bank_of_america\" or \"eye_of_the_beholder\".\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      'npmi' is more robust when dealing with common words that form part of common bigrams, and\n",
      " |      ranges from -1 to 1, but is slower to calculate than the default. The default is the PMI-like scoring\n",
      " |      as described by `Mikolov, et. al: \"Distributed Representations of Words and Phrases and their Compositionality\"\n",
      " |      <https://arxiv.org/abs/1310.4546>`_.\n",
      " |      \n",
      " |      To use a custom scoring function, pass in a function with the following signature:\n",
      " |      \n",
      " |      * worda_count - number of corpus occurrences in `sentences` of the first token in the bigram being scored\n",
      " |      * wordb_count - number of corpus occurrences in `sentences` of the second token in the bigram being scored\n",
      " |      * bigram_count - number of occurrences in `sentences` of the whole bigram\n",
      " |      * len_vocab - the number of unique tokens in `sentences`\n",
      " |      * min_count - the `min_count` setting of the Phrases class\n",
      " |      * corpus_word_count - the total number of tokens (non-unique) in `sentences`\n",
      " |      \n",
      " |      The scoring function **must accept all these parameters**, even if it doesn't use them in its scoring.\n",
      " |      The scoring function **must be pickleable**.\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Get short string representation of this phrase detector.\n",
      " |  \n",
      " |  add_vocab(self, sentences)\n",
      " |      Update model with new `sentences`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sentences : iterable of list of str\n",
      " |          Text corpus.\n",
      " |      \n",
      " |      Example\n",
      " |      -------\n",
      " |      >>> from gensim.test.utils import datapath\n",
      " |      >>> from gensim.models.word2vec import Text8Corpus\n",
      " |      >>> from gensim.models.phrases import Phrases\n",
      " |      >>> #Create corpus and use it for phrase detector\n",
      " |      >>> sentences = Text8Corpus(datapath('testcorpus.txt'))\n",
      " |      >>> phrases = Phrases(sentences)  # train model\n",
      " |      >>> assert len(phrases.vocab) == 37\n",
      " |      >>>\n",
      " |      >>> more_sentences = [\n",
      " |      ...    [u'the', u'mayor', u'of', u'new', u'york', u'was', u'there'],\n",
      " |      ...    [u'machine', u'learning', u'can', u'be', u'new', u'york' , u'sometimes']\n",
      " |      ... ]\n",
      " |      >>>\n",
      " |      >>> phrases.add_vocab(more_sentences)  # add new sentences to model\n",
      " |      >>> assert len(phrases.vocab) == 60\n",
      " |  \n",
      " |  export_phrases(self, sentences, out_delimiter=b' ', as_tuples=False)\n",
      " |      Get all phrases that appear in 'sentences' that pass the bigram threshold.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sentences : iterable of list of str\n",
      " |          Text corpus.\n",
      " |      out_delimiter : str, optional\n",
      " |          Delimiter used to \"glue\" together words that form a bigram phrase.\n",
      " |      as_tuples : bool, optional\n",
      " |          Yield `(tuple(words), score)` instead of `(out_delimiter.join(words), score)`?\n",
      " |      \n",
      " |      Yields\n",
      " |      ------\n",
      " |      ((str, str), float) **or** (str, float)\n",
      " |          Phrases detected in `sentences`. Return type depends on the `as_tuples` parameter.\n",
      " |      \n",
      " |      Example\n",
      " |      -------\n",
      " |      >>> from gensim.test.utils import datapath\n",
      " |      >>> from gensim.models.word2vec import Text8Corpus\n",
      " |      >>> from gensim.models.phrases import Phrases\n",
      " |      >>>\n",
      " |      >>> sentences = Text8Corpus(datapath('testcorpus.txt'))\n",
      " |      >>> phrases = Phrases(sentences, min_count=1, threshold=0.1)\n",
      " |      >>>\n",
      " |      >>> for phrase, score in phrases.export_phrases(sentences):\n",
      " |      ...     pass\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  load(*args, **kwargs) from builtins.type\n",
      " |      Load a previously saved Phrases class.\n",
      " |      Handles backwards compatibility from older Phrases versions which did not support pluggable scoring functions.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      args : object\n",
      " |          Sequence of arguments, see :class:`~gensim.utils.SaveLoad.load` for more information.\n",
      " |      kwargs : object\n",
      " |          Sequence of arguments, see :class:`~gensim.utils.SaveLoad.load` for more information.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  learn_vocab(sentences, max_vocab_size, delimiter=b'_', progress_per=10000, common_terms=frozenset())\n",
      " |      Collect unigram/bigram counts from the `sentences` iterable.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sentences : iterable of list of str\n",
      " |          The `sentences` iterable can be simply a list, but for larger corpora, consider a generator that streams\n",
      " |          the sentences directly from disk/network, See :class:`~gensim.models.word2vec.BrownCorpus`,\n",
      " |          :class:`~gensim.models.word2vec.Text8Corpus` or :class:`~gensim.models.word2vec.LineSentence`\n",
      " |          for such examples.\n",
      " |      max_vocab_size : int\n",
      " |          Maximum size (number of tokens) of the vocabulary. Used to control pruning of less common words,\n",
      " |          to keep memory under control. The default of 40M needs about 3.6GB of RAM. Increase/decrease\n",
      " |          `max_vocab_size` depending on how much available memory you have.\n",
      " |      delimiter : str, optional\n",
      " |          Glue character used to join collocation tokens, should be a byte string (e.g. b'_').\n",
      " |      progress_per : int\n",
      " |          Write logs every `progress_per` sentence.\n",
      " |      common_terms : set of str, optional\n",
      " |          List of \"stop words\" that won't affect frequency count of expressions containing them.\n",
      " |          Allow to detect expressions like \"bank_of_america\" or \"eye_of_the_beholder\".\n",
      " |      \n",
      " |      Return\n",
      " |      ------\n",
      " |      (int, dict of (str, int), int)\n",
      " |          Number of pruned words, counters for each word/bi-gram and total number of words.\n",
      " |      \n",
      " |      Example\n",
      " |      ----------\n",
      " |      >>> from gensim.test.utils import datapath\n",
      " |      >>> from gensim.models.word2vec import Text8Corpus\n",
      " |      >>> from gensim.models.phrases import Phrases\n",
      " |      >>>\n",
      " |      >>> sentences = Text8Corpus(datapath('testcorpus.txt'))\n",
      " |      >>> pruned_words, counters, total_words = Phrases.learn_vocab(sentences, 100)\n",
      " |      >>> (pruned_words, total_words)\n",
      " |      (1, 29)\n",
      " |      >>> counters['computer']\n",
      " |      2\n",
      " |      >>> counters['response_time']\n",
      " |      1\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from SentenceAnalyzer:\n",
      " |  \n",
      " |  analyze_sentence(self, sentence, threshold, common_terms, scorer)\n",
      " |      Analyze a sentence, detecting any bigrams that should be concatenated.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sentence : iterable of str\n",
      " |          Token sequence representing the sentence to be analyzed.\n",
      " |      threshold : float\n",
      " |          The minimum score for a bigram to be taken into account.\n",
      " |      common_terms : list of object\n",
      " |          List of common terms, they receive special treatment.\n",
      " |      scorer : function\n",
      " |          Scorer function, as given to :class:`~gensim.models.phrases.Phrases`.\n",
      " |          See :func:`~gensim.models.phrases.npmi_scorer` and :func:`~gensim.models.phrases.original_scorer`.\n",
      " |      \n",
      " |      Yields\n",
      " |      ------\n",
      " |      (str, score)\n",
      " |          If bi-gram detected, a tuple where the first element is a detect bigram, second its score.\n",
      " |          Otherwise, the first tuple element is a single word and second is None.\n",
      " |  \n",
      " |  score_item(self, worda, wordb, components, scorer)\n",
      " |      Get bi-gram score statistics.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      worda : str\n",
      " |          First word of bi-gram.\n",
      " |      wordb : str\n",
      " |          Second word of bi-gram.\n",
      " |      components : generator\n",
      " |          Contain all phrases.\n",
      " |      scorer : function\n",
      " |          Scorer function, as given to :class:`~gensim.models.phrases.Phrases`.\n",
      " |          See :func:`~gensim.models.phrases.npmi_scorer` and :func:`~gensim.models.phrases.original_scorer`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      float\n",
      " |          Score for given bi-gram. If bi-gram not present in dictionary - return -1.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from SentenceAnalyzer:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from gensim.utils.SaveLoad:\n",
      " |  \n",
      " |  save(self, fname_or_handle, separately=None, sep_limit=10485760, ignore=frozenset(), pickle_protocol=2)\n",
      " |      Save the object to a file.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname_or_handle : str or file-like\n",
      " |          Path to output file or already opened file-like object. If the object is a file handle,\n",
      " |          no special array handling will be performed, all attributes will be saved to the same file.\n",
      " |      separately : list of str or None, optional\n",
      " |          If None, automatically detect large numpy/scipy.sparse arrays in the object being stored, and store\n",
      " |          them into separate files. This prevent memory errors for large objects, and also allows\n",
      " |          `memory-mapping <https://en.wikipedia.org/wiki/Mmap>`_ the large arrays for efficient\n",
      " |          loading and sharing the large arrays in RAM between multiple processes.\n",
      " |      \n",
      " |          If list of str: store these attributes into separate files. The automated size check\n",
      " |          is not performed in this case.\n",
      " |      sep_limit : int, optional\n",
      " |          Don't store arrays smaller than this separately. In bytes.\n",
      " |      ignore : frozenset of str, optional\n",
      " |          Attributes that shouldn't be stored at all.\n",
      " |      pickle_protocol : int, optional\n",
      " |          Protocol number for pickle.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      :meth:`~gensim.utils.SaveLoad.load`\n",
      " |          Load object from file.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['human', 'interface', 'computer'],\n",
       " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
       " ['eps', 'user', 'interface', 'system'],\n",
       " ['system', 'human', 'system', 'eps'],\n",
       " ['user', 'response', 'time'],\n",
       " ['trees'],\n",
       " ['graph', 'trees'],\n",
       " ['graph', 'minors', 'trees'],\n",
       " ['graph', 'minors', 'survey']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_transformer = Phrases(common_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_adapt_by_suffix',\n",
       " '_apply',\n",
       " '_load_specials',\n",
       " '_save_specials',\n",
       " '_smart_save',\n",
       " 'add_vocab',\n",
       " 'analyze_sentence',\n",
       " 'common_terms',\n",
       " 'corpus_word_count',\n",
       " 'delimiter',\n",
       " 'export_phrases',\n",
       " 'learn_vocab',\n",
       " 'load',\n",
       " 'max_vocab_size',\n",
       " 'min_count',\n",
       " 'min_reduce',\n",
       " 'progress_per',\n",
       " 'save',\n",
       " 'score_item',\n",
       " 'scoring',\n",
       " 'threshold',\n",
       " 'vocab']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(bigram_transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method export_phrases in module gensim.models.phrases:\n",
      "\n",
      "export_phrases(sentences, out_delimiter=b' ', as_tuples=False) method of gensim.models.phrases.Phrases instance\n",
      "    Get all phrases that appear in 'sentences' that pass the bigram threshold.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    sentences : iterable of list of str\n",
      "        Text corpus.\n",
      "    out_delimiter : str, optional\n",
      "        Delimiter used to \"glue\" together words that form a bigram phrase.\n",
      "    as_tuples : bool, optional\n",
      "        Yield `(tuple(words), score)` instead of `(out_delimiter.join(words), score)`?\n",
      "    \n",
      "    Yields\n",
      "    ------\n",
      "    ((str, str), float) **or** (str, float)\n",
      "        Phrases detected in `sentences`. Return type depends on the `as_tuples` parameter.\n",
      "    \n",
      "    Example\n",
      "    -------\n",
      "    >>> from gensim.test.utils import datapath\n",
      "    >>> from gensim.models.word2vec import Text8Corpus\n",
      "    >>> from gensim.models.phrases import Phrases\n",
      "    >>>\n",
      "    >>> sentences = Text8Corpus(datapath('testcorpus.txt'))\n",
      "    >>> phrases = Phrases(sentences, min_count=1, threshold=0.1)\n",
      "    >>>\n",
      "    >>> for phrase, score in phrases.export_phrases(sentences):\n",
      "    ...     pass\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(bigram_transformer.export_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim.models.word2vec import Text8Corpus\n",
    "from gensim.models.phrases import Phrases\n",
    "sentences = Text8Corpus(datapath('testcorpus.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Text8Corpus at 0x7fae901939b0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "phrases = Phrases(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {b'computer': 2,\n",
       "             b'computer_human': 1,\n",
       "             b'computer_response': 1,\n",
       "             b'eps': 2,\n",
       "             b'eps_human': 1,\n",
       "             b'eps_response': 1,\n",
       "             b'graph': 3,\n",
       "             b'graph_minors': 2,\n",
       "             b'graph_trees': 1,\n",
       "             b'human': 2,\n",
       "             b'human_interface': 1,\n",
       "             b'human_system': 1,\n",
       "             b'interface': 2,\n",
       "             b'interface_computer': 1,\n",
       "             b'interface_system': 1,\n",
       "             b'minors': 2,\n",
       "             b'minors_survey': 1,\n",
       "             b'response': 2,\n",
       "             b'response_survey': 1,\n",
       "             b'response_time': 1,\n",
       "             b'survey': 2,\n",
       "             b'survey_graph': 1,\n",
       "             b'survey_system': 1,\n",
       "             b'system': 4,\n",
       "             b'system_eps': 1,\n",
       "             b'system_system': 1,\n",
       "             b'system_time': 1,\n",
       "             b'system_user': 1,\n",
       "             b'time': 2,\n",
       "             b'time_user': 2,\n",
       "             b'trees': 3,\n",
       "             b'trees_graph': 2,\n",
       "             b'trees_trees': 1,\n",
       "             b'user': 3,\n",
       "             b'user_eps': 1,\n",
       "             b'user_interface': 1,\n",
       "             b'user_trees': 1})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Phrases in module gensim.models.phrases:\n",
      "\n",
      "class Phrases(SentenceAnalyzer, PhrasesTransformation)\n",
      " |  Detect phrases based on collocation counts.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Phrases\n",
      " |      SentenceAnalyzer\n",
      " |      PhrasesTransformation\n",
      " |      gensim.interfaces.TransformationABC\n",
      " |      gensim.utils.SaveLoad\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getitem__(self, sentence)\n",
      " |      Convert the input tokens `sentence` into tokens where detected bigrams are joined by a selected delimiter.\n",
      " |      \n",
      " |      If `sentence` is an entire corpus (iterable of sentences rather than a single\n",
      " |      sentence), return an iterable that converts each of the corpus' sentences\n",
      " |      into phrases on the fly, one after another.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sentence : {list of str, iterable of list of str}\n",
      " |          Sentence or text corpus.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      {list of str, :class:`gensim.interfaces.TransformedCorpus`}\n",
      " |          `sentence` with detected phrase bigrams merged together, or a streamed corpus of such sentences\n",
      " |          if the input was a corpus.\n",
      " |      \n",
      " |      Examples\n",
      " |      ----------\n",
      " |      >>> from gensim.test.utils import datapath\n",
      " |      >>> from gensim.models.word2vec import Text8Corpus\n",
      " |      >>> from gensim.models.phrases import Phrases, Phraser\n",
      " |      >>>\n",
      " |      >>> #Create corpus\n",
      " |      >>> sentences = Text8Corpus(datapath('testcorpus.txt'))\n",
      " |      >>>\n",
      " |      >>> #Train the detector with:\n",
      " |      >>> phrases = Phrases(sentences, min_count=1, threshold=1)\n",
      " |      >>> #Input is a list of unicode strings:\n",
      " |      >>> sent = [u'trees', u'graph', u'minors']\n",
      " |      >>> #Both of these tokens appear in corpus at least twice, and phrase score is higher, than treshold = 1:\n",
      " |      >>> print(phrases[sent])\n",
      " |      [u'trees_graph', u'minors']\n",
      " |      >>>\n",
      " |      >>> sentences = Text8Corpus(datapath('testcorpus.txt'))\n",
      " |      >>> phrases = Phrases(sentences, min_count=1, threshold=1)\n",
      " |      >>> phraser = Phraser(phrases)  # for speedup\n",
      " |      >>>\n",
      " |      >>> sent = [[u'trees', u'graph', u'minors'],[u'graph', u'minors']]\n",
      " |      >>> for phrase in phraser[sent]:\n",
      " |      ...     pass\n",
      " |  \n",
      " |  __init__(self, sentences=None, min_count=5, threshold=10.0, max_vocab_size=40000000, delimiter=b'_', progress_per=10000, scoring='default', common_terms=frozenset())\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sentences : iterable of list of str, optional\n",
      " |          The `sentences` iterable can be simply a list, but for larger corpora, consider a generator that streams\n",
      " |          the sentences directly from disk/network, See :class:`~gensim.models.word2vec.BrownCorpus`,\n",
      " |          :class:`~gensim.models.word2vec.Text8Corpus` or :class:`~gensim.models.word2vec.LineSentence`\n",
      " |          for such examples.\n",
      " |      min_count : float, optional\n",
      " |          Ignore all words and bigrams with total collected count lower than this value.\n",
      " |      threshold : float, optional\n",
      " |          Represent a score threshold for forming the phrases (higher means fewer phrases).\n",
      " |          A phrase of words `a` followed by `b` is accepted if the score of the phrase is greater than threshold.\n",
      " |          Heavily depends on concrete scoring-function, see the `scoring` parameter.\n",
      " |      max_vocab_size : int, optional\n",
      " |          Maximum size (number of tokens) of the vocabulary. Used to control pruning of less common words,\n",
      " |          to keep memory under control. The default of 40M needs about 3.6GB of RAM. Increase/decrease\n",
      " |          `max_vocab_size` depending on how much available memory you have.\n",
      " |      delimiter : str, optional\n",
      " |          Glue character used to join collocation tokens, should be a byte string (e.g. b'_').\n",
      " |      scoring : {'default', 'npmi', function}, optional\n",
      " |          Specify how potential phrases are scored. `scoring` can be set with either a string that refers to a\n",
      " |          built-in scoring function, or with a function with the expected parameter names.\n",
      " |          Two built-in scoring functions are available by setting `scoring` to a string:\n",
      " |      \n",
      " |          #. \"default\" - :func:`~gensim.models.phrases.original_scorer`.\n",
      " |          #. \"npmi\" - :func:`~gensim.models.phrases.npmi_scorer`.\n",
      " |      common_terms : set of str, optional\n",
      " |          List of \"stop words\" that won't affect frequency count of expressions containing them.\n",
      " |          Allow to detect expressions like \"bank_of_america\" or \"eye_of_the_beholder\".\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      'npmi' is more robust when dealing with common words that form part of common bigrams, and\n",
      " |      ranges from -1 to 1, but is slower to calculate than the default. The default is the PMI-like scoring\n",
      " |      as described by `Mikolov, et. al: \"Distributed Representations of Words and Phrases and their Compositionality\"\n",
      " |      <https://arxiv.org/abs/1310.4546>`_.\n",
      " |      \n",
      " |      To use a custom scoring function, pass in a function with the following signature:\n",
      " |      \n",
      " |      * worda_count - number of corpus occurrences in `sentences` of the first token in the bigram being scored\n",
      " |      * wordb_count - number of corpus occurrences in `sentences` of the second token in the bigram being scored\n",
      " |      * bigram_count - number of occurrences in `sentences` of the whole bigram\n",
      " |      * len_vocab - the number of unique tokens in `sentences`\n",
      " |      * min_count - the `min_count` setting of the Phrases class\n",
      " |      * corpus_word_count - the total number of tokens (non-unique) in `sentences`\n",
      " |      \n",
      " |      The scoring function **must accept all these parameters**, even if it doesn't use them in its scoring.\n",
      " |      The scoring function **must be pickleable**.\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Get short string representation of this phrase detector.\n",
      " |  \n",
      " |  add_vocab(self, sentences)\n",
      " |      Update model with new `sentences`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sentences : iterable of list of str\n",
      " |          Text corpus.\n",
      " |      \n",
      " |      Example\n",
      " |      -------\n",
      " |      >>> from gensim.test.utils import datapath\n",
      " |      >>> from gensim.models.word2vec import Text8Corpus\n",
      " |      >>> from gensim.models.phrases import Phrases\n",
      " |      >>> #Create corpus and use it for phrase detector\n",
      " |      >>> sentences = Text8Corpus(datapath('testcorpus.txt'))\n",
      " |      >>> phrases = Phrases(sentences)  # train model\n",
      " |      >>> assert len(phrases.vocab) == 37\n",
      " |      >>>\n",
      " |      >>> more_sentences = [\n",
      " |      ...    [u'the', u'mayor', u'of', u'new', u'york', u'was', u'there'],\n",
      " |      ...    [u'machine', u'learning', u'can', u'be', u'new', u'york' , u'sometimes']\n",
      " |      ... ]\n",
      " |      >>>\n",
      " |      >>> phrases.add_vocab(more_sentences)  # add new sentences to model\n",
      " |      >>> assert len(phrases.vocab) == 60\n",
      " |  \n",
      " |  export_phrases(self, sentences, out_delimiter=b' ', as_tuples=False)\n",
      " |      Get all phrases that appear in 'sentences' that pass the bigram threshold.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sentences : iterable of list of str\n",
      " |          Text corpus.\n",
      " |      out_delimiter : str, optional\n",
      " |          Delimiter used to \"glue\" together words that form a bigram phrase.\n",
      " |      as_tuples : bool, optional\n",
      " |          Yield `(tuple(words), score)` instead of `(out_delimiter.join(words), score)`?\n",
      " |      \n",
      " |      Yields\n",
      " |      ------\n",
      " |      ((str, str), float) **or** (str, float)\n",
      " |          Phrases detected in `sentences`. Return type depends on the `as_tuples` parameter.\n",
      " |      \n",
      " |      Example\n",
      " |      -------\n",
      " |      >>> from gensim.test.utils import datapath\n",
      " |      >>> from gensim.models.word2vec import Text8Corpus\n",
      " |      >>> from gensim.models.phrases import Phrases\n",
      " |      >>>\n",
      " |      >>> sentences = Text8Corpus(datapath('testcorpus.txt'))\n",
      " |      >>> phrases = Phrases(sentences, min_count=1, threshold=0.1)\n",
      " |      >>>\n",
      " |      >>> for phrase, score in phrases.export_phrases(sentences):\n",
      " |      ...     pass\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  load(*args, **kwargs) from builtins.type\n",
      " |      Load a previously saved Phrases class.\n",
      " |      Handles backwards compatibility from older Phrases versions which did not support pluggable scoring functions.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      args : object\n",
      " |          Sequence of arguments, see :class:`~gensim.utils.SaveLoad.load` for more information.\n",
      " |      kwargs : object\n",
      " |          Sequence of arguments, see :class:`~gensim.utils.SaveLoad.load` for more information.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  learn_vocab(sentences, max_vocab_size, delimiter=b'_', progress_per=10000, common_terms=frozenset())\n",
      " |      Collect unigram/bigram counts from the `sentences` iterable.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sentences : iterable of list of str\n",
      " |          The `sentences` iterable can be simply a list, but for larger corpora, consider a generator that streams\n",
      " |          the sentences directly from disk/network, See :class:`~gensim.models.word2vec.BrownCorpus`,\n",
      " |          :class:`~gensim.models.word2vec.Text8Corpus` or :class:`~gensim.models.word2vec.LineSentence`\n",
      " |          for such examples.\n",
      " |      max_vocab_size : int\n",
      " |          Maximum size (number of tokens) of the vocabulary. Used to control pruning of less common words,\n",
      " |          to keep memory under control. The default of 40M needs about 3.6GB of RAM. Increase/decrease\n",
      " |          `max_vocab_size` depending on how much available memory you have.\n",
      " |      delimiter : str, optional\n",
      " |          Glue character used to join collocation tokens, should be a byte string (e.g. b'_').\n",
      " |      progress_per : int\n",
      " |          Write logs every `progress_per` sentence.\n",
      " |      common_terms : set of str, optional\n",
      " |          List of \"stop words\" that won't affect frequency count of expressions containing them.\n",
      " |          Allow to detect expressions like \"bank_of_america\" or \"eye_of_the_beholder\".\n",
      " |      \n",
      " |      Return\n",
      " |      ------\n",
      " |      (int, dict of (str, int), int)\n",
      " |          Number of pruned words, counters for each word/bi-gram and total number of words.\n",
      " |      \n",
      " |      Example\n",
      " |      ----------\n",
      " |      >>> from gensim.test.utils import datapath\n",
      " |      >>> from gensim.models.word2vec import Text8Corpus\n",
      " |      >>> from gensim.models.phrases import Phrases\n",
      " |      >>>\n",
      " |      >>> sentences = Text8Corpus(datapath('testcorpus.txt'))\n",
      " |      >>> pruned_words, counters, total_words = Phrases.learn_vocab(sentences, 100)\n",
      " |      >>> (pruned_words, total_words)\n",
      " |      (1, 29)\n",
      " |      >>> counters['computer']\n",
      " |      2\n",
      " |      >>> counters['response_time']\n",
      " |      1\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from SentenceAnalyzer:\n",
      " |  \n",
      " |  analyze_sentence(self, sentence, threshold, common_terms, scorer)\n",
      " |      Analyze a sentence, detecting any bigrams that should be concatenated.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sentence : iterable of str\n",
      " |          Token sequence representing the sentence to be analyzed.\n",
      " |      threshold : float\n",
      " |          The minimum score for a bigram to be taken into account.\n",
      " |      common_terms : list of object\n",
      " |          List of common terms, they receive special treatment.\n",
      " |      scorer : function\n",
      " |          Scorer function, as given to :class:`~gensim.models.phrases.Phrases`.\n",
      " |          See :func:`~gensim.models.phrases.npmi_scorer` and :func:`~gensim.models.phrases.original_scorer`.\n",
      " |      \n",
      " |      Yields\n",
      " |      ------\n",
      " |      (str, score)\n",
      " |          If bi-gram detected, a tuple where the first element is a detect bigram, second its score.\n",
      " |          Otherwise, the first tuple element is a single word and second is None.\n",
      " |  \n",
      " |  score_item(self, worda, wordb, components, scorer)\n",
      " |      Get bi-gram score statistics.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      worda : str\n",
      " |          First word of bi-gram.\n",
      " |      wordb : str\n",
      " |          Second word of bi-gram.\n",
      " |      components : generator\n",
      " |          Contain all phrases.\n",
      " |      scorer : function\n",
      " |          Scorer function, as given to :class:`~gensim.models.phrases.Phrases`.\n",
      " |          See :func:`~gensim.models.phrases.npmi_scorer` and :func:`~gensim.models.phrases.original_scorer`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      float\n",
      " |          Score for given bi-gram. If bi-gram not present in dictionary - return -1.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from SentenceAnalyzer:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from gensim.utils.SaveLoad:\n",
      " |  \n",
      " |  save(self, fname_or_handle, separately=None, sep_limit=10485760, ignore=frozenset(), pickle_protocol=2)\n",
      " |      Save the object to a file.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname_or_handle : str or file-like\n",
      " |          Path to output file or already opened file-like object. If the object is a file handle,\n",
      " |          no special array handling will be performed, all attributes will be saved to the same file.\n",
      " |      separately : list of str or None, optional\n",
      " |          If None, automatically detect large numpy/scipy.sparse arrays in the object being stored, and store\n",
      " |          them into separate files. This prevent memory errors for large objects, and also allows\n",
      " |          `memory-mapping <https://en.wikipedia.org/wiki/Mmap>`_ the large arrays for efficient\n",
      " |          loading and sharing the large arrays in RAM between multiple processes.\n",
      " |      \n",
      " |          If list of str: store these attributes into separate files. The automated size check\n",
      " |          is not performed in this case.\n",
      " |      sep_limit : int, optional\n",
      " |          Don't store arrays smaller than this separately. In bytes.\n",
      " |      ignore : frozenset of str, optional\n",
      " |          Attributes that shouldn't be stored at all.\n",
      " |      pickle_protocol : int, optional\n",
      " |          Protocol number for pickle.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      :meth:`~gensim.utils.SaveLoad.load`\n",
      " |          Load object from file.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'fname',\n",
       " 'max_sentence_length']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/usr/local/lib/python3.6/dist-packages/gensim/test/test_data/testcorpus.txt'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences.fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "sent_list = list(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['computer',\n",
       "  'human',\n",
       "  'interface',\n",
       "  'computer',\n",
       "  'response',\n",
       "  'survey',\n",
       "  'system',\n",
       "  'time',\n",
       "  'user',\n",
       "  'interface',\n",
       "  'system',\n",
       "  'user',\n",
       "  'eps',\n",
       "  'human',\n",
       "  'system',\n",
       "  'system',\n",
       "  'eps',\n",
       "  'response',\n",
       "  'time',\n",
       "  'user',\n",
       "  'trees',\n",
       "  'trees',\n",
       "  'graph',\n",
       "  'trees',\n",
       "  'graph',\n",
       "  'minors',\n",
       "  'survey',\n",
       "  'graph',\n",
       "  'minors']]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open(\"douban_data.pkl\", \"rb\") as f:\n",
    "    serlize_data = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in serlize_data.keys():\n",
    "    exec(\"{}=serlize_data['{}']\".format(k, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['美国 队长 钢铁 好像 摇滚圈 五月天 二手 玫瑰',\n",
       " '特地 登陆 打星 星半 半星 一分',\n",
       " '画面 挺不错 变身 很帅 剧情 太弱 点燃 点泪点 几段 打戏 审美疲劳 国产 动画 不错 贡献 票房 心态 电影院',\n",
       " '星爷 确实 掩盖 本片 苍白 命运 功夫 无厘头 无星爷',\n",
       " '剧本 中二 算不得 绝症 青春 玛丽 表达方式 低龄化 一点 程度 打败 富春山 居图 史上 第一 烂片 图森 中国 大陆 商业片 不多见 褒义 场面 调度 加一星 赵薇 感受一下',\n",
       " '乖乖仔 理解 青春 直人 世界 难懂',\n",
       " '周星星 电影 少不了 英雄 情结 一点 依然 感动 一塌糊涂 少女',\n",
       " '至少 真的 不二 神探 好看 太多',\n",
       " '糟糕 特效 原作 看着',\n",
       " '喜中 泪泪 人生']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases_douban = Phrases(train_cut_result + test_cut_result, max_vocab_size=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18969"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(phrases_douban.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "collections.defaultdict"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(phrases_douban.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'美国'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(phrases_douban.vocab.keys())[0].decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'美国_队长': 181,\n",
       " '队长_钢铁': 11,\n",
       " '剧情_太弱': 27,\n",
       " '国产_动画': 204,\n",
       " '动画_不错': 12,\n",
       " '贡献_票房': 26,\n",
       " '富春山_居图': 28,\n",
       " '中国_大陆': 5,\n",
       " '场面_调度': 9,\n",
       " '感动_一塌糊涂': 6,\n",
       " '好看_太多': 7,\n",
       " '超级_喜欢': 22,\n",
       " '搞笑_成分': 8,\n",
       " '哈哈哈_哈哈哈': 57,\n",
       " '涵予_彭于': 5,\n",
       " '一星_特效': 56,\n",
       " '人生_赢家': 5,\n",
       " '留下_深刻印象': 6,\n",
       " '再也_不看': 15,\n",
       " '核心_价值观': 7,\n",
       " '电影_生活': 7,\n",
       " '生活_方式': 7,\n",
       " '真的_喜欢': 58,\n",
       " '再也_不想': 10,\n",
       " '剧情_单薄': 45,\n",
       " '不错_国产': 23,\n",
       " '爆米花_电影': 214,\n",
       " '电影_情节': 55,\n",
       " '好看_喜欢': 41,\n",
       " '画面_特效': 19,\n",
       " '想起_一句': 6,\n",
       " '实在_不想': 11,\n",
       " '整部_电影': 181,\n",
       " '逻辑_混乱': 34,\n",
       " '无聊_透顶': 16,\n",
       " '环保_主题': 38,\n",
       " '确实_好笑': 6,\n",
       " '剧情_画面': 28,\n",
       " '实在_太赞': 6,\n",
       " '不错_电影': 105,\n",
       " '电影_完整': 7,\n",
       " '完整_故事': 32,\n",
       " '实在_理解': 12,\n",
       " '理解_电影': 12,\n",
       " '电影_剧情': 124,\n",
       " '剧情_逻辑': 50,\n",
       " '友谊_小船': 12,\n",
       " '心疼_托尼': 8,\n",
       " '配角_演技': 5,\n",
       " '真的_无聊': 28,\n",
       " '火星_救援': 9,\n",
       " '一群_动物': 7,\n",
       " '剧情_老套': 108,\n",
       " '一部_电影': 394,\n",
       " '电影_好看': 130,\n",
       " '英雄主义_电影': 11,\n",
       " '闺蜜_之间': 9,\n",
       " '电影_精彩': 21,\n",
       " '同期_电影': 11,\n",
       " '效果_不错': 87,\n",
       " '不错_音乐': 18,\n",
       " '感觉_一部': 23,\n",
       " '一部_中国': 12,\n",
       " '一部_一部': 45,\n",
       " '出乎_意料': 5,\n",
       " '真的_不错': 85,\n",
       " '台词_功力': 15,\n",
       " '简单_故事': 26,\n",
       " '现实_社会': 6,\n",
       " '舒服_电影': 7,\n",
       " '电影_感觉': 106,\n",
       " '看着_看着': 36,\n",
       " '感觉_烂片': 8,\n",
       " '蜜汁_尴尬': 7,\n",
       " '尴尬_演技': 13,\n",
       " '搞笑_方式': 9,\n",
       " '感觉_不错': 92,\n",
       " '不错_特效': 35,\n",
       " '星爷_无厘头': 18,\n",
       " '好看_感觉': 18,\n",
       " '特效_就值': 8,\n",
       " '更新_吴亦凡': 5,\n",
       " '功夫_瑜伽': 8,\n",
       " '这部_电影': 914,\n",
       " '人设_不错': 5,\n",
       " '不错_女主': 9,\n",
       " '剧情_发展': 45,\n",
       " '节奏_紧凑': 37,\n",
       " '忠于_原著': 19,\n",
       " '尴尬_剧情': 23,\n",
       " '剧情_不错': 60,\n",
       " '不错_算是': 10,\n",
       " '期待_电影': 24,\n",
       " '感觉_失望': 10,\n",
       " '发现_这部': 6,\n",
       " '过渡_自然': 7,\n",
       " '生硬_情节': 5,\n",
       " '血腥_暴力': 24,\n",
       " '剧情_完整': 12,\n",
       " '只能_特效': 8,\n",
       " '特效_电影': 18,\n",
       " '电影_肯定': 14,\n",
       " '电影_元素': 9,\n",
       " '满怀_期待': 16,\n",
       " '电影_还好': 11,\n",
       " '口音_出戏': 6,\n",
       " '美式_幽默': 9,\n",
       " '演员_演技': 175,\n",
       " '电影_电影': 96,\n",
       " '电影_小说': 39,\n",
       " '小说_小说': 8,\n",
       " '不错_人物': 8,\n",
       " '人物_关系': 27,\n",
       " '看过_第一部': 9,\n",
       " '第一部_电影': 52,\n",
       " '表演_可圈可点': 6,\n",
       " '世界_其他人': 8,\n",
       " '大圣_归来': 86,\n",
       " '中国_导演': 16,\n",
       " '真实_事件': 53,\n",
       " '拯救_世界': 69,\n",
       " '喜欢_罗伯特': 10,\n",
       " '罗伯特_唐尼': 46,\n",
       " '期望_太高': 58,\n",
       " '不错_剧情': 145,\n",
       " '剧情_不行': 23,\n",
       " '说实话_电影': 12,\n",
       " '演技_在线': 43,\n",
       " '看过_原著': 154,\n",
       " '原著_特效': 7,\n",
       " '舒淇_文章': 10,\n",
       " '剧情_无力': 15,\n",
       " '无力_吐槽': 86,\n",
       " '广告_植入': 66,\n",
       " '中国_演员': 20,\n",
       " '片子_电影院': 6,\n",
       " '植入_广告': 77,\n",
       " '片子_真的': 24,\n",
       " '真的_合适': 6,\n",
       " '喜欢_韩寒': 17,\n",
       " '支持_国产': 42,\n",
       " '国产_动漫': 46,\n",
       " '希望_越来越': 9,\n",
       " '西游_伏妖': 20,\n",
       " '一个半_小时': 23,\n",
       " '剧情_简单': 81,\n",
       " '电影_特效': 56,\n",
       " '特效_音乐': 7,\n",
       " '音乐_画面': 23,\n",
       " '不错_地方': 9,\n",
       " '值得_电影院': 28,\n",
       " '中国_文化': 24,\n",
       " '超级_英雄': 328,\n",
       " '来拉低_评分': 7,\n",
       " '评分_真的': 9,\n",
       " '电影_看着': 11,\n",
       " '看着_睡着': 19,\n",
       " '树懒_搞笑': 6,\n",
       " '主旋律_电影': 40,\n",
       " '电影_一半': 15,\n",
       " '一半_实在': 16,\n",
       " '实在_看不下去': 44,\n",
       " '希望_续集': 10,\n",
       " '冬雨_适合': 6,\n",
       " '适合_小孩': 7,\n",
       " '电影_人性': 16,\n",
       " '丧尸_电影': 27,\n",
       " '特效_不错': 248,\n",
       " '不错_故事': 54,\n",
       " '故事_台词': 10,\n",
       " '莫名其妙_爱情': 6,\n",
       " '青春_电影': 91,\n",
       " '电影_永远': 11,\n",
       " '青春_感觉': 12,\n",
       " '感觉_美国': 6,\n",
       " '电影_套路': 14,\n",
       " '政治_正确': 79,\n",
       " '一部_不错': 36,\n",
       " '电影_起码': 5,\n",
       " '喜欢_类型': 45,\n",
       " '豆瓣_评分': 183,\n",
       " '成龙_大哥': 126,\n",
       " '经典_成龙': 6,\n",
       " '成龙_电影': 92,\n",
       " '冬雨_演技': 66,\n",
       " '真的_理解': 8,\n",
       " '情怀_电影': 11,\n",
       " '电影_东西': 9,\n",
       " '好莱坞_大片': 65,\n",
       " '电影_节奏': 27,\n",
       " '人设_剧情': 5,\n",
       " '剧情_推进': 12,\n",
       " '剧情_没什么': 27,\n",
       " '浪费_题材': 5,\n",
       " '韩寒_风格': 23,\n",
       " '追逐_梦想': 16,\n",
       " '梦想_努力': 17,\n",
       " '喜欢_钢铁': 29,\n",
       " '钢铁_造型': 9,\n",
       " '故事_单薄': 13,\n",
       " '星爷_星爷': 10,\n",
       " '九层_妖塔': 166,\n",
       " '鬼吹灯_关系': 12,\n",
       " '一星_老师': 10,\n",
       " '老师_一星': 8,\n",
       " '拉低_分数': 13,\n",
       " '不错_好看': 16,\n",
       " '两个_演技': 5,\n",
       " '一半_不想': 5,\n",
       " '细节_很棒': 6,\n",
       " '真的_难看': 31,\n",
       " '确实_很棒': 7,\n",
       " '结局_不错': 7,\n",
       " '触动_人心': 9,\n",
       " '垃圾_电影': 46,\n",
       " '电影_人生': 6,\n",
       " '相遇_久别重逢': 14,\n",
       " '这部_片子': 240,\n",
       " '本来_喜欢': 9,\n",
       " '还好_看过': 9,\n",
       " '电影_带来': 5,\n",
       " '三颗_星给': 13,\n",
       " '冬雨_马思纯': 12,\n",
       " '马思纯_演技': 17,\n",
       " '电影_主题': 14,\n",
       " '道理_依然': 7,\n",
       " '依然_不好': 8,\n",
       " '不好_一生': 9,\n",
       " '人生_大道理': 7,\n",
       " '四星_五星': 19,\n",
       " '本来_三星': 40,\n",
       " '這部_電影': 10,\n",
       " '制作_精良': 57,\n",
       " '人物_情节': 11,\n",
       " '剧情_超级': 5,\n",
       " '手动_再见': 21,\n",
       " '夏洛特_烦恼': 42,\n",
       " '西天_取经': 6,\n",
       " '本来_期待': 18,\n",
       " '节奏_把握': 20,\n",
       " '漫威_出品': 7,\n",
       " '真的_不到': 8,\n",
       " '屌丝_意淫': 13,\n",
       " '女人_男人': 6,\n",
       " '一般般_特效': 5,\n",
       " '真的_好看': 125,\n",
       " '好看_真的': 18,\n",
       " '真的_感动': 30,\n",
       " '真的_剧情': 21,\n",
       " '角色_名字': 5,\n",
       " '系列_剧情': 6,\n",
       " '剧情_不合理': 10,\n",
       " '长得_好看': 11,\n",
       " '莫名_奇妙': 22,\n",
       " '一个多_小时': 33,\n",
       " '小时_时间': 12,\n",
       " '大陆_电影': 11,\n",
       " '电影_真的': 113,\n",
       " '真的_不想': 18,\n",
       " '安生_安生': 23,\n",
       " '喜欢_安生': 21,\n",
       " '活成_七月': 8,\n",
       " '金士杰_配音': 6,\n",
       " '片子_唯一': 6,\n",
       " '人世间_相遇': 6,\n",
       " '值回_票价': 57,\n",
       " '打斗_场面': 89,\n",
       " '看过_九层': 11,\n",
       " '贴合_原著': 5,\n",
       " '特效_震撼': 10,\n",
       " '视觉_冲击': 13,\n",
       " '五毛_特效': 19,\n",
       " '特效_国产': 11,\n",
       " '国产_商业片': 15,\n",
       " '青春_故事': 19,\n",
       " '故事_感动': 13,\n",
       " '作品_剧情': 6,\n",
       " '剧情_地方': 12,\n",
       " '特效_满分': 20,\n",
       " '电影_青春': 16,\n",
       " '长江_七号': 10,\n",
       " '西游_降魔': 72,\n",
       " '喜欢_西游': 11,\n",
       " '情节_紧凑': 46,\n",
       " '典型_好莱坞': 21,\n",
       " '视觉_疲劳': 15,\n",
       " '有下_一部': 5,\n",
       " '一点_关系': 6,\n",
       " '几个_镜头': 21,\n",
       " '几个_男人': 5,\n",
       " '复仇者_联盟': 101,\n",
       " '明白_多人': 15,\n",
       " '感觉_还好': 7,\n",
       " '还好_特效': 5,\n",
       " '不错_搞笑': 19,\n",
       " '影院_笑声': 9,\n",
       " '支持_星爷': 19,\n",
       " '节奏_太快': 15,\n",
       " '剧情_特效': 68,\n",
       " '特效_五毛': 12,\n",
       " '主演_演技': 13,\n",
       " '演技_出色': 5,\n",
       " '剧情_演员': 21,\n",
       " '用力_过猛': 23,\n",
       " '评分_虚高': 26,\n",
       " '淡淡的_青春': 27,\n",
       " '青春_纯纯': 24,\n",
       " '两颗_星给': 26,\n",
       " '一部_动画片': 14,\n",
       " '真的_这部': 10,\n",
       " '青春_青春': 27,\n",
       " '第一部_丧尸': 9,\n",
       " '国内_动画': 5,\n",
       " '动画_良心': 13,\n",
       " '善良_对错': 5,\n",
       " '电影_喜欢': 71,\n",
       " '半个_小时': 54,\n",
       " '小时_实在': 5,\n",
       " '三星_画面': 18,\n",
       " '故事_感觉': 17,\n",
       " '喜欢_男主角': 5,\n",
       " '小说_电影': 67,\n",
       " '画面_音乐': 84,\n",
       " '音乐_剧情': 15,\n",
       " '整体_水平': 5,\n",
       " '电影_中国': 25,\n",
       " '负分_选项': 5,\n",
       " '垃圾_战斗机': 13,\n",
       " '搞笑_片段': 7,\n",
       " '教育_意义': 11,\n",
       " '画风_剧情': 9,\n",
       " '剧情_配乐': 8,\n",
       " '新人_导演': 10,\n",
       " '导演_不错': 10,\n",
       " '冬雨_表演': 10,\n",
       " '电影_值得一看': 13,\n",
       " '浮于_表面': 6,\n",
       " '豆瓣_评价': 9,\n",
       " '讲完_故事': 7,\n",
       " '故事_故事': 28,\n",
       " '逻辑_错误': 6,\n",
       " '英雄_喜欢': 10,\n",
       " '典型_成龙': 28,\n",
       " '一星_片尾': 11,\n",
       " '感觉_第一部': 16,\n",
       " '片子_好看': 27,\n",
       " '电影_不错': 106,\n",
       " '视听_盛宴': 10,\n",
       " '拉低_平均分': 6,\n",
       " '睡着_一星': 5,\n",
       " '还好_电影院': 13,\n",
       " '电影_配乐': 14,\n",
       " '剧情_平淡': 18,\n",
       " '漫画_改编': 6,\n",
       " '看过_美国': 6,\n",
       " '美国_丧尸': 5,\n",
       " '上映_第一天': 12,\n",
       " '恶意_差评': 6,\n",
       " '烂片_烂片': 44,\n",
       " '一星_颜值': 6,\n",
       " '水平_剧情': 7,\n",
       " '一场_电影': 18,\n",
       " '电影_一场': 11,\n",
       " '把握_不错': 11,\n",
       " '开头_那段': 7,\n",
       " '一点_不好': 19,\n",
       " '动作_镜头': 6,\n",
       " '迪士尼_梦工厂': 6,\n",
       " '硬汉_彭于': 6,\n",
       " '没什么_感觉': 30,\n",
       " '快乐_大本营': 12,\n",
       " '人生_第一次': 7,\n",
       " '蜘蛛_可爱': 13,\n",
       " '搞笑_特别': 6,\n",
       " '里算_不错': 10,\n",
       " '韩寒_小说': 18,\n",
       " '小时_电影': 18,\n",
       " '电影_结束': 50,\n",
       " '结束_感觉': 6,\n",
       " '感觉_像是': 29,\n",
       " '特效_很棒': 45,\n",
       " '很棒_剧情': 20,\n",
       " '电影_看过': 28,\n",
       " '看过_最烂': 23,\n",
       " '最烂_电影': 19,\n",
       " '电影_上映': 34,\n",
       " '画面_很漂亮': 6,\n",
       " '真心_喜欢': 17,\n",
       " '电影_浪费': 7,\n",
       " '感觉_好看': 19,\n",
       " '星爷_电影票': 18,\n",
       " '场面_宏大': 34,\n",
       " '故事_简单': 37,\n",
       " '感觉_故事': 27,\n",
       " '马特_达蒙': 64,\n",
       " '鹿晗_演技': 13,\n",
       " '感动_剧情': 7,\n",
       " '剧情_走向': 15,\n",
       " '画面_唯美': 39,\n",
       " '结局_圆满': 5,\n",
       " '猩红_女巫': 24,\n",
       " '剧情_薄弱': 21,\n",
       " '看着_尴尬': 13,\n",
       " '真的_不怎么样': 11,\n",
       " '配乐_一星': 8,\n",
       " '葫芦娃_大战': 8,\n",
       " '大战_奥特曼': 6,\n",
       " '烂片_剧情': 11,\n",
       " '剧情_乱七八糟': 18,\n",
       " '中国_电影': 175,\n",
       " '电影_超级': 8,\n",
       " '丧尸_人性': 12,\n",
       " '丧尸_丧尸': 9,\n",
       " '电影院_睡着': 56,\n",
       " '一分_特效': 21,\n",
       " '商业片_特效': 5,\n",
       " '特效_场面': 13,\n",
       " '好看_国产': 8,\n",
       " '国产_奇幻': 7,\n",
       " '节奏_混乱': 9,\n",
       " '人物_塑造': 45,\n",
       " '喜欢_老师': 14,\n",
       " '演技_特别': 8,\n",
       " '特别_特别': 12,\n",
       " '一点_好看': 27,\n",
       " '一星_剧情': 14,\n",
       " '剧情_一星': 13,\n",
       " '期待_失望': 19,\n",
       " '拼凑_剧情': 6,\n",
       " '剧情_剧情': 33,\n",
       " '疯狂_动物': 15,\n",
       " '一部_作品': 29,\n",
       " '剧情_不好': 9,\n",
       " '也许_期望': 6,\n",
       " '太太_太太': 7,\n",
       " '感觉_钢铁': 5,\n",
       " '文艺_青年': 32,\n",
       " '感动_电影': 21,\n",
       " '电影_男主': 5,\n",
       " '印象_深刻': 65,\n",
       " '电影_告诉': 18,\n",
       " '珍惜_身边': 15,\n",
       " '大鱼_海棠': 74,\n",
       " '衔接_生硬': 8,\n",
       " '演技_演技': 11,\n",
       " '表演_做作': 7,\n",
       " '电影_表达': 25,\n",
       " '节奏_太慢': 8,\n",
       " '剧情_拖沓': 67,\n",
       " '拖沓_剧情': 9,\n",
       " '确实_剧情': 17,\n",
       " '陆川_导演': 16,\n",
       " '导演_作品': 17,\n",
       " '营销_成功': 8,\n",
       " '无厘头_搞笑': 17,\n",
       " '情节_人物': 11,\n",
       " '打动_观众': 6,\n",
       " '好看_中国': 7,\n",
       " '不想_第二遍': 7,\n",
       " '喜欢_文艺片': 5,\n",
       " '两个_主角': 9,\n",
       " '主角_颜值': 9,\n",
       " '只能_及格': 8,\n",
       " '开心_麻花': 56,\n",
       " '电影_话剧': 8,\n",
       " '演员_表演': 68,\n",
       " '导演_表达': 17,\n",
       " '珍惜_眼前': 32,\n",
       " '紧张_刺激': 26,\n",
       " '水军_真的': 5,\n",
       " '一点_小说': 5,\n",
       " '小说_改编': 27,\n",
       " '导演_功力': 23,\n",
       " '配乐_画面': 11,\n",
       " '搞笑_哈哈哈': 6,\n",
       " '以往_青春片': 5,\n",
       " '不错_开头': 6,\n",
       " '那段_精彩': 6,\n",
       " '剧情_电影': 26,\n",
       " '电影_搞笑': 17,\n",
       " '搞笑_片子': 7,\n",
       " '成龙_动作片': 11,\n",
       " '剧情_硬伤': 61,\n",
       " '一部_看过': 9,\n",
       " '苏有朋_导演': 15,\n",
       " '导演_演员': 29,\n",
       " '爱情_爱错': 35,\n",
       " '爱错_青春': 35,\n",
       " '国产_青春片': 34,\n",
       " '剧情_设计': 12,\n",
       " '实属_不易': 6,\n",
       " '剧情_无聊': 56,\n",
       " '实在_太烂': 11,\n",
       " '豆瓣_沦陷': 5,\n",
       " '整体_不错': 41,\n",
       " '算是_国产片': 6,\n",
       " '标准_好莱坞': 13,\n",
       " '故事_完整': 47,\n",
       " '特效_惊艳': 7,\n",
       " '感觉_特别': 15,\n",
       " '剧情_混乱': 22,\n",
       " '没什么_看点': 9,\n",
       " '电影_心情': 6,\n",
       " '期望值_太高': 20,\n",
       " '国内_不错': 7,\n",
       " '民族_自豪感': 6,\n",
       " '喜欢_蜘蛛': 6,\n",
       " '结尾_彩蛋': 26,\n",
       " '画面_故事': 34,\n",
       " '制作_用心': 15,\n",
       " '用心_一部': 6,\n",
       " '绯红_女巫': 18,\n",
       " '真的_很棒': 24,\n",
       " '特效_确实': 29,\n",
       " '确实_不错': 69,\n",
       " '剧情_不太': 5,\n",
       " '三打_白骨精': 6,\n",
       " '画面_精美': 26,\n",
       " '结尾_太仓促': 10,\n",
       " '强强_联手': 7,\n",
       " '全场_爆笑': 14,\n",
       " '一部_贺岁片': 6,\n",
       " '星爷_粉丝': 5,\n",
       " '粉丝_电影': 24,\n",
       " '星爷_真的': 12,\n",
       " '喜欢_故事': 27,\n",
       " '真的_好帅': 11,\n",
       " '特效_真的': 48,\n",
       " '真的_震撼': 10,\n",
       " '吴亦凡_唐僧': 8,\n",
       " '两部_片子': 8,\n",
       " '片子_中国': 6,\n",
       " '喜欢_徐峥': 6,\n",
       " '本来_不想': 12,\n",
       " '喜欢_小说': 22,\n",
       " '不错_画面': 22,\n",
       " '当年_喜欢': 6,\n",
       " '中文_配音': 14,\n",
       " '国内_电影': 18,\n",
       " '电影_水平': 9,\n",
       " '时代_系列': 11,\n",
       " '系列_电影': 21,\n",
       " '佩服_佩服': 7,\n",
       " '看过_电影': 91,\n",
       " '徐峥_导演': 7,\n",
       " '演得_不错': 13,\n",
       " '演技_实在': 11,\n",
       " '没什么_关系': 8,\n",
       " '看着_开心': 7,\n",
       " '舒淇_女神': 10,\n",
       " '大写_尴尬': 10,\n",
       " '场面_震撼': 19,\n",
       " '一部_值得': 21,\n",
       " '片子_片子': 9,\n",
       " '电影_评价': 23,\n",
       " '电影_一点': 16,\n",
       " '剧情_真的': 85,\n",
       " '相忘_江湖': 10,\n",
       " '还原_真实': 5,\n",
       " '电影_记得': 7,\n",
       " '感觉_这部': 21,\n",
       " '欠星爷_电影票': 12,\n",
       " '唐僧_悟空': 7,\n",
       " '美国_英雄': 18,\n",
       " '电影_故事': 41,\n",
       " '故事_内容': 15,\n",
       " '老套_特效': 5,\n",
       " '特效_精彩': 5,\n",
       " '一把_年纪': 18,\n",
       " '豆瓣_高分': 11,\n",
       " '狗血_套路': 8,\n",
       " '夏雨_演技': 8,\n",
       " '电影_亚洲': 5,\n",
       " '网上_评论': 5,\n",
       " '画面_质感': 9,\n",
       " '不错_情节': 27,\n",
       " '青春_疼痛': 17,\n",
       " '青春_友谊': 6,\n",
       " '侮辱_智商': 16,\n",
       " '故事_狗血': 12,\n",
       " '无论是_剧情': 6,\n",
       " '剧情_演技': 37,\n",
       " '演技_很棒': 14,\n",
       " '故事_不好': 14,\n",
       " '拍摄_手法': 35,\n",
       " '走进_电影院': 9,\n",
       " '美队_钢铁': 15,\n",
       " '钢铁_绿巨人': 20,\n",
       " '动作_喜剧': 13,\n",
       " '画面_不错': 76,\n",
       " '逻辑_硬伤': 15,\n",
       " '剧情_理解': 6,\n",
       " '电影_剪辑': 10,\n",
       " '实在_太差': 5,\n",
       " '结尾_仓促': 17,\n",
       " '笑点_泪点': 21,\n",
       " '牵挂_牵挂': 20,\n",
       " '豆瓣_影评': 21,\n",
       " '两星_一颗': 5,\n",
       " '演员_演绎': 5,\n",
       " '人物_设定': 34,\n",
       " '安生_七月': 59,\n",
       " '很久没_看过': 12,\n",
       " '电影_这部': 34,\n",
       " '感觉_时间': 11,\n",
       " '时间_流逝': 6,\n",
       " '拍摄_技巧': 7,\n",
       " '故事_背景': 18,\n",
       " '故事_算是': 6,\n",
       " '算是_国产': 22,\n",
       " '烂片_豆瓣': 6,\n",
       " '男女_主角': 95,\n",
       " '音乐_好听': 42,\n",
       " '画面_精致': 11,\n",
       " '演员_服装': 7,\n",
       " '道士_下山': 7,\n",
       " '实在_中国': 5,\n",
       " '深刻_内涵': 7,\n",
       " '一部_喜剧': 26,\n",
       " '恶心_剧情': 8,\n",
       " '反正_好看': 13,\n",
       " '更新_演技': 16,\n",
       " '这部_影片': 62,\n",
       " '结局_美好': 11,\n",
       " '星爷_作品': 13,\n",
       " '特效_剧情': 100,\n",
       " '剧情_细节': 15,\n",
       " '三星_是因为': 9,\n",
       " '特效_一星': 38,\n",
       " '演技_硬伤': 10,\n",
       " '对白_生硬': 5,\n",
       " '真的_讨厌': 10,\n",
       " '三星_电影': 21,\n",
       " '电影_高分': 7,\n",
       " '特别_喜欢': 46,\n",
       " '画面_美的': 27,\n",
       " '评分_忽悠': 5,\n",
       " '浪费_时间': 17,\n",
       " '一分_不想': 7,\n",
       " '不错_支持': 10,\n",
       " '舞蹈_音乐': 10,\n",
       " '音乐_电影': 11,\n",
       " '导演_真的': 10,\n",
       " '气氛_渲染': 6,\n",
       " '看得_尴尬': 33,\n",
       " '失望_剧情': 17,\n",
       " '电影_第一': 6,\n",
       " '几部_电影': 12,\n",
       " '结尾_感人': 6,\n",
       " '超级_好看': 35,\n",
       " '超出_预期': 42,\n",
       " '万年_备胎': 7,\n",
       " '新海_动画': 8,\n",
       " '动画_剧情': 13,\n",
       " '剧情_特别': 10,\n",
       " '特别_矫情': 6,\n",
       " '秒速_厘米': 22,\n",
       " '电影_三星': 27,\n",
       " '华语_电影': 20,\n",
       " '电影_周星驰': 16,\n",
       " '周星驰_徐克': 24,\n",
       " '全程_尴尬': 31,\n",
       " '打发_时间': 35,\n",
       " '不太_喜欢': 43,\n",
       " '时代_这部': 8,\n",
       " '这部_小说': 15,\n",
       " '至少_一部': 6,\n",
       " '导演_能力': 8,\n",
       " '不错_结局': 10,\n",
       " '配乐_不错': 21,\n",
       " '台词_搞笑': 5,\n",
       " '整场_电影': 13,\n",
       " '唯一_一部': 29,\n",
       " '好看_期待': 9,\n",
       " '期待_一部': 30,\n",
       " '样子_喜欢': 7,\n",
       " '三个_女生': 6,\n",
       " '特效_特效': 40,\n",
       " '特效_凑合': 6,\n",
       " '不值_票价': 9,\n",
       " '编剧_好好': 7,\n",
       " '原著_改编': 6,\n",
       " '欧豪_演技': 10,\n",
       " '好看_演技': 8,\n",
       " '梦想_梦想': 17,\n",
       " '印象_最深': 31,\n",
       " '树懒_那段': 20,\n",
       " '俗套_故事': 15,\n",
       " '音乐_梦想': 8,\n",
       " '梦想_爱情': 31,\n",
       " '场面_不错': 31,\n",
       " '不错_整体': 11,\n",
       " '整体_结构': 7,\n",
       " '剧情_设置': 15,\n",
       " '真心_好看': 50,\n",
       " '越来越_电影': 5,\n",
       " '电影_票房': 16,\n",
       " '剧情_紧凑': 82,\n",
       " '感情_铺垫': 9,\n",
       " '七月_安生': 164,\n",
       " '片尾曲_好听': 7,\n",
       " '中国_元素': 100,\n",
       " '时代_栀子花': 6,\n",
       " '剧情_确实': 28,\n",
       " '剧情_逻辑性': 6,\n",
       " '大片_剧情': 12,\n",
       " '越高_失望': 10,\n",
       " '豆瓣_负分': 16,\n",
       " '演技_剧情': 25,\n",
       " '剧情_拖拉': 11,\n",
       " '特效_一无是处': 9,\n",
       " '故事_老套': 31,\n",
       " '感觉_适合': 5,\n",
       " '演员_演得': 7,\n",
       " '故事_明白': 10,\n",
       " '真的_垃圾': 12,\n",
       " '那种_感觉': 25,\n",
       " '感觉_一般般': 11,\n",
       " '剧情_节奏': 23,\n",
       " '表演_浮夸': 8,\n",
       " '故作_深沉': 12,\n",
       " '三观_不正': 125,\n",
       " '不正_三观': 8,\n",
       " '国产_喜剧片': 13,\n",
       " '一万年_太久': 39,\n",
       " '太久_只争朝夕': 21,\n",
       " '喜欢_这部': 68,\n",
       " '电影_图个': 10,\n",
       " '电影_豆瓣': 32,\n",
       " '片子_票房': 10,\n",
       " '真的_看不下去': 15,\n",
       " '喜欢_邓超': 8,\n",
       " '青春_主题': 7,\n",
       " '怀旧_青春': 18,\n",
       " '剧情_狗血': 75,\n",
       " '交换_人生': 8,\n",
       " '好看_感人': 9,\n",
       " '演员_很棒': 10,\n",
       " '一星_画面': 33,\n",
       " '画面_一星': 30,\n",
       " '没什么_剧情': 26,\n",
       " '速五_厘米': 16,\n",
       " '交换_身体': 23,\n",
       " '期待_这部': 12,\n",
       " '电影_失望': 28,\n",
       " '失望_特效': 9,\n",
       " '电影_公司': 6,\n",
       " '喜欢_电影': 68,\n",
       " '电影_发现': 18,\n",
       " '电影_两个': 22,\n",
       " '两个_半小时': 19,\n",
       " '走进_影院': 9,\n",
       " '电影_好莱坞': 7,\n",
       " '视觉_大片': 6,\n",
       " '梦想_现实': 14,\n",
       " '推荐_这部': 8,\n",
       " '疼痛_青春': 11,\n",
       " '情感_表达': 8,\n",
       " '李易峰_蒋劲夫': 10,\n",
       " '全片_亮点': 12,\n",
       " '任性_五星': 5,\n",
       " '迪士尼_动画': 16,\n",
       " '一毛钱_关系': 11,\n",
       " '女主角_演技': 11,\n",
       " '演技_尴尬': 57,\n",
       " '电影_几个': 9,\n",
       " '老师_电影': 10,\n",
       " '迪士尼_动画片': 6,\n",
       " '四星_剧情': 8,\n",
       " '叙事_手法': 8,\n",
       " '剧情_令人': 6,\n",
       " '画面_满分': 16,\n",
       " '满分_故事': 6,\n",
       " '幽默_搞笑': 10,\n",
       " '搞笑_星爷': 5,\n",
       " '负责_搞笑': 9,\n",
       " '事件_改编': 29,\n",
       " '画面_音效': 8,\n",
       " '太高_感觉': 8,\n",
       " '李珥_张漾': 8,\n",
       " '豆瓣_分数': 15,\n",
       " '也许_适合': 5,\n",
       " '感觉_网上': 7,\n",
       " '效果_剧情': 24,\n",
       " '特效_画面': 16,\n",
       " '满分_剧情': 18,\n",
       " '电视剧_版本': 7,\n",
       " '超级_难看': 5,\n",
       " '漫威_宇宙': 15,\n",
       " '收官_之作': 5,\n",
       " '啊啊啊_啊啊啊': 34,\n",
       " '演员_台词': 10,\n",
       " '全程无_尿点': 55,\n",
       " '不想_吐槽': 27,\n",
       " '电影_中有': 7,\n",
       " '笑点_演技': 6,\n",
       " '比小_时代': 28,\n",
       " '演员_导演': 24,\n",
       " '喜欢_郭采洁': 6,\n",
       " '斯嘉丽_约翰逊': 10,\n",
       " '评分_太高': 11,\n",
       " '成龙_地方': 9,\n",
       " '地方_执行': 9,\n",
       " '执行_轻易': 9,\n",
       " '轻易_闯入': 9,\n",
       " '闯入_轻易': 9,\n",
       " '轻易_得手': 9,\n",
       " '得手_离开': 9,\n",
       " '离开_发现': 9,\n",
       " '发现_大打': 9,\n",
       " '大打_一架': 9,\n",
       " '一架_成龙': 6,\n",
       " '电影_评分': 25,\n",
       " '期望_过高': 21,\n",
       " '韩国_电影': 95,\n",
       " '相爱_相杀': 20,\n",
       " '安妮_宝贝': 95,\n",
       " '爆裂_鼓手': 7,\n",
       " '预告片_好看': 7,\n",
       " '故事_结局': 11,\n",
       " '真的_很难': 11,\n",
       " '第二部_电影': 5,\n",
       " '电影_充满': 10,\n",
       " '画面_一流': 5,\n",
       " '场面_精彩': 15,\n",
       " '预期_好看': 8,\n",
       " '片子_适合': 7,\n",
       " '剧情_实在': 51,\n",
       " '实在_接受': 8,\n",
       " '接受_无能': 13,\n",
       " '全场_笑点': 13,\n",
       " '一句_台词': 27,\n",
       " '演技_爆发': 8,\n",
       " '喜欢_放肆': 28,\n",
       " '放肆_克制': 22,\n",
       " '小说_结局': 7,\n",
       " '好评_如潮': 11,\n",
       " '好莱坞_爆米花': 8,\n",
       " '剧情_反转': 14,\n",
       " '反转_反转': 9,\n",
       " '期待_第二部': 13,\n",
       " '感觉_剧情': 53,\n",
       " '没什么_情节': 11,\n",
       " '剧情_跳跃': 16,\n",
       " '演员_做作': 6,\n",
       " '商业_烂片': 9,\n",
       " '感觉_电视剧': 9,\n",
       " '电视剧_好看': 40,\n",
       " '演技_生硬': 18,\n",
       " '生硬_剧情': 7,\n",
       " '剧情_女主': 8,\n",
       " '不错_细节': 10,\n",
       " '盗墓_笔记': 48,\n",
       " '不想_承认': 11,\n",
       " '承认_看过': 10,\n",
       " '一星_马思纯': 5,\n",
       " '画面_效果': 19,\n",
       " '不错_片子': 23,\n",
       " '杨洋_颜值': 9,\n",
       " '真的_真的': 26,\n",
       " '电影_水军': 10,\n",
       " '制作_画面': 7,\n",
       " '画面_剧情': 61,\n",
       " '剧情_垃圾': 15,\n",
       " '电影_看得': 14,\n",
       " '大哥_电影': 21,\n",
       " '电影_一贯': 13,\n",
       " '一颗_星给': 150,\n",
       " '感觉_电影': 51,\n",
       " '特别_出彩': 8,\n",
       " '出彩_地方': 9,\n",
       " '快餐_电影': 7,\n",
       " '本来_打算': 11,\n",
       " '星爷_一星': 12,\n",
       " '场景_音乐': 6,\n",
       " '看不惯_一股': 7,\n",
       " '一股_高傲': 7,\n",
       " '高傲_劲儿': 7,\n",
       " '劲儿_冗长': 7,\n",
       " '冗长_小时': 8,\n",
       " '算是_一部': 18,\n",
       " '电影_台词': 13,\n",
       " '星给_特效': 16,\n",
       " '笑点_尴尬': 17,\n",
       " '功夫_熊猫': 18,\n",
       " '叙事_能力': 8,\n",
       " '美好_爱情': 11,\n",
       " '几位_演员': 6,\n",
       " '颜值_剧情': 10,\n",
       " '剧情_一分': 11,\n",
       " '电影_导演': 26,\n",
       " '片子_值得': 9,\n",
       " '星爷_电影': 68,\n",
       " '电影_演员': 18,\n",
       " '影院_效果': 13,\n",
       " '第一次_电影院': 42,\n",
       " '日本_动漫': 19,\n",
       " '动漫_电影': 11,\n",
       " '喜欢_真的': 7,\n",
       " '传统_文化': 16,\n",
       " '电影_结局': 9,\n",
       " '评分_真心': 7,\n",
       " '尴尬_特效': 12,\n",
       " '电影_场景': 12,\n",
       " '场景_切换': 6,\n",
       " '真的_不好': 18,\n",
       " '出新_高度': 9,\n",
       " '周星驰_电影票': 8,\n",
       " '电影票_电影': 7,\n",
       " '反正_感觉': 5,\n",
       " '星爷_片子': 16,\n",
       " '真的_感觉': 17,\n",
       " '留下_印象': 6,\n",
       " '电影_标准': 7,\n",
       " '商业_电影': 54,\n",
       " '电影_效果': 11,\n",
       " '题材_真的': 5,\n",
       " '适合_角色': 19,\n",
       " '结局_喜欢': 9,\n",
       " '美好_结局': 9,\n",
       " '漫威_英雄': 14,\n",
       " '电影_场面': 11,\n",
       " '电影_成龙': 10,\n",
       " '片子_感觉': 17,\n",
       " '评价_这部': 10,\n",
       " '一贯_风格': 26,\n",
       " '依然_喜欢': 10,\n",
       " '美队_系列': 10,\n",
       " '懒得_吐槽': 9,\n",
       " '看过_小说': 157,\n",
       " '国产_不错': 11,\n",
       " '剧情_太过': 14,\n",
       " '一颗_送给': 8,\n",
       " '搞笑_感人': 9,\n",
       " '两个_小时': 86,\n",
       " '差点_睡着': 47,\n",
       " '恶心_电影': 14,\n",
       " '冲着_原著': 5,\n",
       " '特效_国产片': 8,\n",
       " '特效_期待': 5,\n",
       " '两个_女主': 12,\n",
       " '一部_爱情': 8,\n",
       " '爱情_电影': 31,\n",
       " '回到_高中': 5,\n",
       " '高中_大学': 9,\n",
       " '几次_差点': 5,\n",
       " '高中_时期': 7,\n",
       " '景甜_戏份': 6,\n",
       " '至少_这部': 8,\n",
       " '五星_好评': 16,\n",
       " '终于_明白': 11,\n",
       " '开头_剧情': 6,\n",
       " '剧情_生硬': 21,\n",
       " '英雄_题材': 7,\n",
       " '混乱_故事': 5,\n",
       " '看得_过瘾': 5,\n",
       " '值得_票价': 14,\n",
       " '画面_确实': 23,\n",
       " '惊艳_剧情': 8,\n",
       " '电影_表现': 18,\n",
       " '追求_梦想': 32,\n",
       " '爱情_梦想': 31,\n",
       " '幸好_电影院': 14,\n",
       " '特效_情节': 14,\n",
       " '剧情_破碎': 5,\n",
       " '服装_不错': 5,\n",
       " '不错_结尾': 11,\n",
       " '不错_想象': 15,\n",
       " '莫名其妙_喜欢': 7,\n",
       " '分钟_出戏': 46,\n",
       " '片子_实在': 13,\n",
       " '理解_好看': 5,\n",
       " '导演_智商': 5,\n",
       " '舒淇_一星': 8,\n",
       " '这是_时代': 6,\n",
       " '时代_时代': 12,\n",
       " '安生_两个': 5,\n",
       " '韩寒_电影': 20,\n",
       " '值得_推荐': 32,\n",
       " '故事_讲完': 7,\n",
       " '期待_太高': 50,\n",
       " '事情_发生': 8,\n",
       " '支持_国漫': 13,\n",
       " '剧情_笑点': 9,\n",
       " '平凡_之路': 14,\n",
       " '分数_虚高': 14,\n",
       " '整部_影片': 27,\n",
       " '缉毒_警察': 33,\n",
       " '爱国主义_教育': 9,\n",
       " '画风_喜欢': 11,\n",
       " '算是_良心': 10,\n",
       " '良心_之作': 74,\n",
       " '说实话_失望': 5,\n",
       " '故事情节_老套': 5,\n",
       " '喜欢_演员': 17,\n",
       " '画面_很美': 22,\n",
       " '电影_丧尸': 6,\n",
       " '揭露_人性': 5,\n",
       " '爱情_亲情': 7,\n",
       " '亲情_友情': 14,\n",
       " ...}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(filter(lambda tt2: \"_\" in tt2[0] ,map(lambda t2: (t2[0].decode(), t2[1]), phrases_douban.vocab.items())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
